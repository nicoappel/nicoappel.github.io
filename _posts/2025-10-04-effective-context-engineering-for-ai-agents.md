---
karakeep_id: "tbw2pyt20cnc2fo4gpnqnqrf"
title: "Effective context engineering for AI agents"
url: "https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents?utm_source=substack&utm_medium=email"
created: "2025-10-02 18:17:33"
type: "link"
tags: ["Prompt Engineering", "Context Engineering", "Artificial Intelligence", "Large Language Models", "AI Agents"]
published: true
---

Trying to leverage AI to create content ends up in creating a better or worse version of AI slop.
  
That's the rule. Everything else is a rare exception.

My working hypothesis and basis for current experiments is that we have to work backwards, meaningâ€¦
  
How to even have a chance of landing in exception land?
Context engineering.

This is the not only the logical, but technically necessary consequence of LLMs becoming more "agentic", meaning they run tools in a loop to achieve a goal.

During that process, the models are prompting themselves more than the user does. They tend to call that "thinking", but it isn't really.

However, the key then is to manage or engineer context.

That in itself is an "art and a science", which usually means that there are parts known and parts you have to FAFO.

In order to have context that you can do any engineering with, you need something that sounds even more boring and less enticing: 
Documentation.

Yup, in the end, you canâ€™t create all the context every freaking time on the fly. Hence, you use AI to help you extract implicit knowledge, gather available information and organize it.

Because this is the thing: AI can create pretty good, if not excellent, documentation. 
And in that context, tone and style is not an issue. Documentation style is what it is, as long as you tame the verbosity.

If you start there, you build a solid foundation for fancy stuff. 

More on that soon.

[ðŸ”— anthropic.com](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents?utm_source=substack&utm_medium=email)